\documentclass[11pt]{article}

\usepackage[a4paper,margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  urlcolor=blue
}

\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  columns=fullflexible,
  frame=single,
  backgroundcolor=\color{gray!5}
}

\title{Numerical Programming Final Project (Task 2)\\Transition to New Year Greeting}
\author{Student: \textbf{(Andria Gvaramia)} \quad Course: Numerical Programming \quad KIU}
\date{\today}

\begin{document}
\maketitle

\section*{Task statement}
\textbf{Input:} drone swarm at the handwritten name (Task 1 final formation) and the greeting text \textit{``Happy New Year!''}.\\
\textbf{Goal:} move the swarm from the handwritten name positions to the holiday greeting positions.\\
\textbf{Output:} trajectory of each drone and visualization whose input is the trajectory.

\section{Overview}
Task 2 is implemented as a transition between two static point sets:
\begin{itemize}
  \item \textbf{Start formation (Task 1)}: points in \texttt{task1/outputs/target\_points.csv}.
  \item \textbf{Target formation (Task 2 greeting)}: points in \texttt{task2/outputs/target\_points.csv}.
\end{itemize}

The greeting image is generated in \texttt{task2/inputs/greeting.png} and target points are extracted using the same tool as Task 1 (\texttt{task1/extract\_target\_points.py}). The transition trajectories are generated by \texttt{task2/transition.py} using a \textbf{BVP solved via shooting}.

\section{Input data}
\subsection{Greeting image}
The greeting image is produced programmatically (OpenCV text rendering) by:
\begin{lstlisting}
python3 task2/generate_greeting_image.py --out task2/inputs/greeting.png
\end{lstlisting}

\subsection{Target point extraction}
We extract $N$ target points from the greeting image (typically in skeleton / medial-axis mode):
\begin{lstlisting}
python3 task1/extract_target_points.py \
  --image task2/inputs/greeting.png \
  --n 100 --mode skeleton --min-target-spacing 5 \
  --out-dir task2/outputs --debug-png
\end{lstlisting}

\textbf{Important constraint:} the number of drones must match in both tasks:
\[
N_{\text{start}} = N_{\text{target}}.
\]
In practice, the same \texttt{--n} is used in Task 1 and Task 2.

\section{Mathematical model}
We work in 2D pixel coordinates. For each drone $i$ we use a second-order point-mass model:
\[
x_i(t)\in\mathbb{R}^2,\qquad v_i(t)\in\mathbb{R}^2.
\]

\subsection{Dynamics}
The per-drone ODE used in \texttt{task2/transition.py} is:
\begin{align}
\dot{x}_i(t) &= v_i(t),\\
\dot{v}_i(t) &= \frac{1}{m}\left(k_p\,(T_i-x_i(t)) - k_d\,v_i(t)\right).
\end{align}
Here $T_i\in\mathbb{R}^2$ is the \textbf{fixed} greeting target assigned to drone $i$.

\subsection{Boundary value problem (BVP)}
Task 2 is formulated as a boundary value problem:
\[
x_i(0)=x_{i,0}\quad\text{(from Task 1)},\qquad x_i(T)=T_i\quad\text{(greeting targets)}.
\]

\section{Numerical method: shooting}
We solve the BVP via \textbf{shooting}. For each drone, the unknown is the initial velocity $v_i(0)$.
\begin{itemize}
  \item Given a guess $v_i(0)$, we integrate the ODE from $t=0$ to $t=T$ using \texttt{solve\_ivp} (RK45).
  \item We compute the terminal error $F(v_i(0)) = x_i(T;v_i(0)) - T_i$.
  \item We update $v_i(0)$ using a nonlinear solver.
\end{itemize}

\subsection{Reducing end oscillation}
To reduce overshoot near the end, we optionally solve a least-squares problem that also prefers $v_i(T)\approx 0$:
\[
r(v_0)=\big[x(T;v_0)-T,\; w_v\,v(T;v_0)\big],
\]
enabled via:
\begin{lstlisting}
--bvp-match-final-velocity --bvp-final-velocity-weight 3.0
\end{lstlisting}

\section{Collision discussion and verification}
\textbf{This Task 2 shooting implementation solves drones independently} (no inter-drone repulsion term), therefore collision-free motion is \textbf{not guaranteed} by the model.

However, we can \textbf{verify} whether collisions occurred by measuring the minimum pairwise distance over time:
\[
d_{\min}=\min_{t}\min_{i<j}\|x_i(t)-x_j(t)\|.
\]
The script reports the closest approach using:
\begin{lstlisting}
--collision-report --collision-threshold 12
\end{lstlisting}

\section{Reproducibility (commands)}
All commands are run from the project root.

\subsection{Task 1 (ensure start formation with N drones)}
\begin{lstlisting}
python3 task1/extract_target_points.py --n 100 --mode skeleton --min-target-spacing 5 --debug-png
\end{lstlisting}

\subsection{Task 2 (transition)}
\begin{lstlisting}
python3 task2/transition.py \
  --start task1/outputs/target_points.csv \
  --targets task2/outputs/target_points.csv \
  --bg-target task2/inputs/greeting.png \
  --bvp-match-final-velocity --bvp-final-velocity-weight 3.0 \
  --k-p 2.0 --k-d 2.5 \
  --t-end 20 --steps 200 \
  --collision-report --collision-threshold 12 \
  --save-gif --save-traj-csv --save-traj-npy --save-traj-plot
\end{lstlisting}

\section{Outputs}
Generated outputs are written to \texttt{task2/outputs/}:
\begin{itemize}
  \item \texttt{transition\_motion.gif}
  \item \texttt{transition\_trajectories.png}
  \item \texttt{transition\_trajectories.csv} and \texttt{transition\_trajectories.npy}
  \item \texttt{target\_points.csv/.npy} and \texttt{debug\_target\_points.png} for the greeting
\end{itemize}

\section{Limitations}
\begin{itemize}
  \item Shooting is per-drone and does not enforce collision avoidance.
  \item Large $N$ increases runtime because shooting solves many small IVPs (one per drone, potentially multiple times due to root finding).
  \item The quality of the greeting formation depends on the target point extraction parameters (mode, spacing, and $N$).
\end{itemize}

\section{AI usage disclosure}
This project was developed with AI assistance (ChatGPT) used for:
\begin{itemize}
  \item explaining BVP and shooting concepts,
  \item proposing model/parameter adjustments,
  \item helping implement and debug Python code, CLI arguments, and visualization.
\end{itemize}

\end{document}

