\documentclass[11pt]{article}

\usepackage[a4paper,margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  urlcolor=blue,
  citecolor=blue
}

\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  columns=fullflexible,
  frame=single,
  backgroundcolor=\color{gray!5}
}

\title{Numerical Programming Final Project (Task 1)\\Static Formation on a Handwritten Input}
\author{Student: \textbf{(Andria Gvaramia)} \quad Course: Numerical Programming \quad KIU}
\date{\today}

\begin{document}
\maketitle

\section*{Task statement}
\textbf{Input:} an image of a handwritten name (at least 8 characters), number of drones $N$, and a still initial configuration.\\
\textbf{Goal:} a drone swarm must move from the still initial formation and form the handwritten name.\\
\textbf{Output:} trajectory of each drone and visualization whose input is the trajectory.

\section{Overview of the implemented pipeline}
The implementation is split into three parts:
\begin{itemize}
  \item \textbf{Target point extraction} from \texttt{task1/inputs/name.png}: produces $N$ target points in pixel coordinates $(x,y)$ saved as \texttt{task1/outputs/target\_points.csv} and \texttt{task1/outputs/target\_points.npy}.
  \item \textbf{Trajectory generation} using \textbf{swarm IVP with repulsion} in \texttt{task1/simulate\_drones.py}.
  \item \textbf{Visualization}: static trajectory plot and an animation (GIF or on-screen) showing drones moving toward the targets.
\end{itemize}

\section{Input data and preprocessing}
\subsection{Binarization}
The handwritten name image is loaded and binarized using OpenCV:
\[
\text{binary}(x,y)=
\begin{cases}
255 & \text{foreground (ink)}\\
0 & \text{background}
\end{cases}
\]
using \texttt{THRESH\_BINARY\_INV}, so the ink becomes white (255). This makes subsequent distance transform and skeletonization operations straightforward.

\subsection{Target points}
The final targets are a set of $N$ pixel coordinates:
\[
T_i = (x_i^{\star}, y_i^{\star}), \quad i=1,\dots,N,
\]
stored in \texttt{target\_points.csv} (header: \texttt{x,y}) and \texttt{target\_points.npy}.

Three extraction modes were used during development:
\begin{itemize}
  \item \textbf{Contour sampling} (points on the boundary).
  \item \textbf{Interior sampling} using distance transform (points inside strokes, away from boundaries).
  \item \textbf{Skeleton (medial axis)} sampling via Zhang--Suen thinning (points lie on the centerline of the letters).
\end{itemize}
To reduce congestion and improve readability, a \textbf{minimum target spacing} can be enforced.

\paragraph{Optional debug figure.}
If generated, \texttt{debug\_target\_points.png} overlays the selected target points on the skeleton or mask.

% \begin{figure}[h]
% \centering
% \includegraphics[width=0.85\linewidth]{../outputs/debug_target_points.png}
% \caption{Extracted target points (debug visualization).}
% \end{figure}

\section{Mathematical models}
All models are implemented in 2D image coordinates (origin at top-left, $y$ increases downward), consistent with plotting settings.

\subsection{State definition}
For drone $i$:
\[
x_i(t)\in\mathbb{R}^2,\quad v_i(t)\in\mathbb{R}^2.
\]

\subsection{BVP model (via shooting)}
The project slides also allow BVP formulations:
\[
x_i(0)=x_{i,0},\qquad x_i(T)=T_i.
\]
In this project, a practical BVP solver is implemented using \textbf{shooting}:
\begin{itemize}
  \item unknowns: initial velocity $v_i(0)$ for each drone,
  \item integrate the (single-drone) second-order ODE from $t=0$ to $t=T$,
  \item adjust $v_i(0)$ (root finding / least squares) until $x_i(T)\approx T_i$.
\end{itemize}

\textbf{Important limitation:} the shooting implementation solves drones \emph{independently} (no inter-drone coupling). Therefore it is excellent for hitting targets, but it does not guarantee collision-free motion.

\subsection{Swarm IVP model with repulsion (collision-free)}
To enforce collision avoidance we also solve a coupled IVP model for the whole swarm:
\begin{align}
\dot{x}_i(t) &= v_i(t),\\
\dot{v}_i(t) &= \frac{1}{m}\left(k_p\,(T_i-x_i(t)) + \sum_{j\neq i} f_{\mathrm{rep}}(x_i,x_j) - k_d\,v_i(t)\right),
\end{align}
where $f_{\mathrm{rep}}$ is an inverse-cube repulsive force active inside a safety radius $R_{\mathrm{safe}}$.
This model is integrated for all drones together, so interactions are included and collisions are avoided in practice.

\section{Numerical methods}
\subsection{Shooting for BVP}
For each drone, a nonlinear system is solved in the unknown initial velocity. Two modes exist:
\begin{itemize}
  \item \textbf{Position-only}: solve $F(v_0)=x(T;v_0)-T=0$ via root finding.
  \item \textbf{Position + final-velocity damping}: solve in least-squares sense using residual
  \[
  r(v_0)=\big[x(T;v_0)-T,\; w_v\,v(T;v_0)\big],
  \]
  which reduces end oscillations by encouraging $v(T)\approx 0$.
\end{itemize}

\subsection{Swarm IVP integration}
We integrate the coupled system with \texttt{solve\_ivp} (RK45). Repulsion is computed at each step using the current drone positions, and velocity can be saturated to respect a maximum speed.

\section{Initialization and assignment}
\subsection{Initial formations}
The initial configuration is a still formation such as:
\begin{itemize}
  \item a horizontal line below the name (\texttt{hline\_below}),
  \item a horizontal line matching each target's $x$ coordinate (\texttt{hline\_match\_targets\_x}),
  \item two horizontal lines below (\texttt{two\_hlines\_below}).
\end{itemize}
Minimum spacing between drones in the initial formation is enforced to prevent immediate collisions.

\subsection{Drone-to-target assignment}
In the implemented Task 1 setup, drone $i$ is assigned to target $T_i$ (row-wise indexing in \texttt{target\_points.csv}).
During development, sorting target points (e.g., by $x$ or by $y$) was used to reduce crossing trajectories.

\section{Reproducibility (commands)}
All experiments are reproducible from the project root.

\subsection{Extract targets (example)}
\begin{lstlisting}
python3 extract_target_points.py --n 100 --mode skeleton \
  --min-target-spacing 5 --debug-png
\end{lstlisting}

\subsection{Swarm IVP (collision-free)}
\begin{lstlisting}
python3 task1/simulate_drones.py \
  --model swarm --k-rep 200 --r-safe 12 \
  --targets task1/outputs/target_points.csv --bg-image task1/inputs/name.png \
  --initial hline_below --offset 50 \
  --k-p 2.0 --k-d 2.5 --v-max 1e9 --t-end 20 --steps 200 --show
\end{lstlisting}

\section{Validation and test cases}
\subsection{Metrics}
Two practical metrics were used:
\begin{itemize}
  \item \textbf{Target accuracy}: $\|x_i(T)-T_i\|$ (mean/max over drones).
  \item \textbf{Safety}: minimum pairwise distance $\min_{i<j,t}\|x_i(t)-x_j(t)\|$ and/or collision count for a chosen threshold.
\end{itemize}

\subsection{Expected behavior}
\begin{itemize}
  \item \textbf{BVP shooting} should hit targets very well, but may allow path crossings because inter-drone coupling is not modeled.
  \item \textbf{Trajectory Optimization} can trade off smoothness vs.\ collision avoidance via weights; it is slower but often yields more controlled behavior.
\end{itemize}

\subsection{Limitations}
\begin{itemize}
  \item \textbf{BVP shooting limitation}: independent drones $\Rightarrow$ no collision-free guarantee.
\item \textbf{Swarm IVP}: strong repulsion can slow convergence to the target shape; requires tuning $k_{\mathrm{rep}}$ and $R_{\mathrm{safe}}$.
\end{itemize}

\section{AI usage disclosure}
This project was developed with AI assistance (ChatGPT) used for:
\begin{itemize}
  \item explaining BVP and shooting concepts,
  \item proposing model/parameter adjustments,
  \item helping implement and debug Python code, CLI arguments, and visualization.
\end{itemize}
All final code and results were verified by running the scripts locally and inspecting outputs.

\section*{Files included in the submission}
\begin{itemize}
  \item Code: \texttt{task1/extract\_target\_points.py}, \texttt{task1/simulate\_drones.py}, \texttt{task1/sort\_target\_points.py}
  \item Input: \texttt{task1/inputs/name.png}
  \item Generated data (reproducible): files in \texttt{task1/outputs/} (targets, trajectories, plots, animations)
  \item This report: \texttt{task1/report/main.tex}
\end{itemize}

\end{document}

